[dev]
# flask server
flask.server.port = 8082
work.thread.count=20
server.root.site = predictor
product.name=predictor

# where to load model
# 由于模型可能是多个级联，所以这里把加载模型的路径写成一个简单的json字符串
model.dir=/home/jiuxiao/NLP/mxnet/ernie_ner/model_dir/model_dir_map.json
#model.dir=/nas/ernie_model/model_path/model_dir_map.json
label_map = /home/jiuxiao/NLP/mxnet/ernie_ner/label_map/label_map.json
#label_map = /nas/ernie_model/label_map/label_map.json
input.size=1,3,224,224

max_seqlen=256
batch_size=32
cased=False
from_pretrained=bert_12_768_12
dropout_prob=0.1
gpu=0

# task and result
max_task_num=16
max_request_time=1
max_get_time=0.05
max_batch_size=16

# different device uses different config
device.type=cpu

# predictor config
get.predictor.timeout=0.5
cpu.predictor.count=2
cpu.enable_mkl=False

gpu.predictor.count=1
gpu.predictor.memory=200
gpu.predictor.device.id=0

# executor config
get.executor.timeout=0.5
cpu.executor.count=2
gpu.executor.count=1
gpu.executor.device.id=0


